{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6971638,"sourceType":"datasetVersion","datasetId":3961875},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\ndata_sets = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    \n    for filename in filenames:\n        print(filename)\n        if filename == \"test_essays.csv\":\n            test = pd.read_csv(os.path.join(dirname, filename))\n        if filename == \"train_essays.csv\":\n            train = pd.read_csv(os.path.join(dirname, filename))\n        if filename == \"train_essays_RDizzl3_seven_v2.csv\":\n            generated_text = pd.read_csv(os.path.join(dirname, filename))\n        if filename == \"train_v2_drcat_02.csv\":\n            generated_text2 = pd.read_csv(os.path.join(dirname, filename))\n        data_sets.append(pd.read_csv(os.path.join(dirname, filename)))\n    print(f\"{len(data_sets)} data sets loaded in.\")\n    \n    \n#test = train[10:100]\n#sample_sub, training_prompts, test, train, _, _, _, generated_text = data_sets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-20T22:37:27.074464Z","iopub.execute_input":"2023-11-20T22:37:27.075153Z","iopub.status.idle":"2023-11-20T22:37:35.617257Z","shell.execute_reply.started":"2023-11-20T22:37:27.075104Z","shell.execute_reply":"2023-11-20T22:37:35.616106Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"0 data sets loaded in.\nsample_submission.csv\ntrain_prompts.csv\ntest_essays.csv\ntrain_essays.csv\n4 data sets loaded in.\ntrain_v2_drcat_02.csv\n5 data sets loaded in.\ntrain_essays_RDizzl3_seven_v2.csv\ntrain_essays_7_prompts_v2.csv\ntrain_essays_7_prompts.csv\ntrain_essays_RDizzl3_seven_v1.csv\n9 data sets loaded in.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Supplementary dataset features:\")\nprint(generated_text.dtypes)\nprint(\"Supplementary dataset2 features:\")\nprint(generated_text2.dtypes)\nprint(\"\\nOriginal dataset features:\")\nprint(train.dtypes)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:35.619442Z","iopub.execute_input":"2023-11-20T22:37:35.619822Z","iopub.status.idle":"2023-11-20T22:37:35.628993Z","shell.execute_reply.started":"2023-11-20T22:37:35.619752Z","shell.execute_reply":"2023-11-20T22:37:35.627522Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Supplementary dataset features:\ntext     object\nlabel     int64\ndtype: object\nSupplementary dataset2 features:\ntext             object\nlabel             int64\nprompt_name      object\nsource           object\nRDizzl3_seven      bool\ndtype: object\n\nOriginal dataset features:\nid           object\nprompt_id     int64\ntext         object\ngenerated     int64\ndtype: object\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As we can see, we need to make it so that these share a universal format so that we can combine the data together.","metadata":{}},{"cell_type":"code","source":"# Rename the label column to match original dataset\ngenerated_text.rename(columns={'label': 'generated'}, inplace=True)\ngenerated_text","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:35.630706Z","iopub.execute_input":"2023-11-20T22:37:35.631304Z","iopub.status.idle":"2023-11-20T22:37:35.669429Z","shell.execute_reply.started":"2023-11-20T22:37:35.631256Z","shell.execute_reply":"2023-11-20T22:37:35.668107Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                    text  generated\n0      Cars. Cars have been around since they became ...          0\n1      Transportation is a large necessity in most co...          0\n2      \"America's love affair with it's vehicles seem...          0\n3      How often do you ride in a car? Do you drive a...          0\n4      Cars are a wonderful thing. They are perhaps o...          0\n...                                                  ...        ...\n17246  Dear Senator,\\n\\nI am writing to you today to ...          1\n17247  Dear Senator,\\n\\nI am writing to you today to ...          1\n17248  Dear Senator,\\n\\nI am writing to you today to ...          1\n17249  Dear Senator,\\n\\nI am writing to you today to ...          1\n17250  Dear Senator,\\n\\nI am writing to you today to ...          1\n\n[17251 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17246</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17247</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17248</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17249</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17250</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>17251 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Drop the two columns we don't need for training\ngenerated_text2.drop('source', axis='columns', inplace=True)\ngenerated_text2.drop('prompt_name', axis='columns', inplace=True)\ngenerated_text2.drop('RDizzl3_seven', axis='columns', inplace=True)\ngenerated_text2.rename(columns={'label': 'generated'}, inplace=True)\ngenerated_text2","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:35.672430Z","iopub.execute_input":"2023-11-20T22:37:35.672812Z","iopub.status.idle":"2023-11-20T22:37:35.703875Z","shell.execute_reply.started":"2023-11-20T22:37:35.672756Z","shell.execute_reply":"2023-11-20T22:37:35.702742Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                    text  generated\n0      Phones\\n\\nModern humans today are always on th...          0\n1      This essay will explain if drivers should or s...          0\n2      Driving while the use of cellular devices\\n\\nT...          0\n3      Phones & Driving\\n\\nDrivers should not be able...          0\n4      Cell Phone Operation While Driving\\n\\nThe abil...          0\n...                                                  ...        ...\n44863  Dear Senator,\\n\\nI am writing to you today to ...          1\n44864  Dear Senator,\\n\\nI am writing to you today to ...          1\n44865  Dear Senator,\\n\\nI am writing to you today to ...          1\n44866  Dear Senator,\\n\\nI am writing to you today to ...          1\n44867  Dear Senator,\\n\\nI am writing to you today to ...          1\n\n[44868 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones\\n\\nModern humans today are always on th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices\\n\\nT...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44863</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44864</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44865</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44866</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44867</th>\n      <td>Dear Senator,\\n\\nI am writing to you today to ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>44868 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.drop('id', axis='columns', inplace=True)\ntrain.drop('prompt_id', axis='columns', inplace=True)\ntrain","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:35.705493Z","iopub.execute_input":"2023-11-20T22:37:35.705839Z","iopub.status.idle":"2023-11-20T22:37:35.722506Z","shell.execute_reply.started":"2023-11-20T22:37:35.705806Z","shell.execute_reply":"2023-11-20T22:37:35.721446Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                   text  generated\n0     Cars. Cars have been around since they became ...          0\n1     Transportation is a large necessity in most co...          0\n2     \"America's love affair with it's vehicles seem...          0\n3     How often do you ride in a car? Do you drive a...          0\n4     Cars are a wonderful thing. They are perhaps o...          0\n...                                                 ...        ...\n1373  There has been a fuss about the Elector Colleg...          0\n1374  Limiting car usage has many advantages. Such a...          0\n1375  There's a new trend that has been developing f...          0\n1376  As we all know cars are a big part of our soci...          0\n1377  Cars have been around since the 1800's and hav...          0\n\n[1378 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1373</th>\n      <td>There has been a fuss about the Elector Colleg...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1374</th>\n      <td>Limiting car usage has many advantages. Such a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1375</th>\n      <td>There's a new trend that has been developing f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1376</th>\n      <td>As we all know cars are a big part of our soci...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1377</th>\n      <td>Cars have been around since the 1800's and hav...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1378 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"training_set = pd.concat([generated_text, train])\ntraining_set = pd.concat([generated_text2, training_set])","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:35.724027Z","iopub.execute_input":"2023-11-20T22:37:35.724371Z","iopub.status.idle":"2023-11-20T22:37:35.737577Z","shell.execute_reply.started":"2023-11-20T22:37:35.724341Z","shell.execute_reply":"2023-11-20T22:37:35.736437Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"training_set['generated'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:35.739239Z","iopub.execute_input":"2023-11-20T22:37:35.739675Z","iopub.status.idle":"2023-11-20T22:37:35.755873Z","shell.execute_reply.started":"2023-11-20T22:37:35.739634Z","shell.execute_reply":"2023-11-20T22:37:35.754631Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"generated\n0    42993\n1    20504\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"## Undersample to get an even distribution","metadata":{}},{"cell_type":"code","source":"pos = training_set[training_set['generated']==1]\nneg = training_set[training_set['generated']==0]\nneg = neg.sample(n=len(pos), random_state = 21)\n\ntraining_set = pd.concat([pos, neg])","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:35.757275Z","iopub.execute_input":"2023-11-20T22:37:35.758481Z","iopub.status.idle":"2023-11-20T22:37:35.786629Z","shell.execute_reply.started":"2023-11-20T22:37:35.758431Z","shell.execute_reply":"2023-11-20T22:37:35.785249Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"training_set['generated'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:35.788001Z","iopub.execute_input":"2023-11-20T22:37:35.788315Z","iopub.status.idle":"2023-11-20T22:37:35.798818Z","shell.execute_reply.started":"2023-11-20T22:37:35.788287Z","shell.execute_reply":"2023-11-20T22:37:35.797562Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"generated\n1    20504\n0    20504\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport keras_nlp\nimport keras_core as keras\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n   \n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.metrics import BinaryAccuracy\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:35.803469Z","iopub.execute_input":"2023-11-20T22:37:35.803964Z","iopub.status.idle":"2023-11-20T22:37:53.109346Z","shell.execute_reply.started":"2023-11-20T22:37:35.803911Z","shell.execute_reply":"2023-11-20T22:37:53.108083Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Using TensorFlow backend\n","output_type":"stream"}]},{"cell_type":"code","source":"isRealTest = True\n\nif isRealTest:\n    X_train = training_set['text'].values\n    y_train = training_set['generated'].values\n    \n    X_test = test['text'].values\n    X_testIDs = test['id']\n    \n    \nelse:\n    X = training_set['text']\n    y = training_set['generated']\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:53.110783Z","iopub.execute_input":"2023-11-20T22:37:53.111560Z","iopub.status.idle":"2023-11-20T22:37:53.120350Z","shell.execute_reply.started":"2023-11-20T22:37:53.111525Z","shell.execute_reply":"2023-11-20T22:37:53.119500Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"max_words = 10000\npadding_length = 200\n\ntokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(X_train)\n\n# Tokenize them into vectors\n# Each unique word represented by an integer\nX_train_sequences = tokenizer.texts_to_sequences(X_train)\nX_test_sequences = tokenizer.texts_to_sequences(X_test)\n\n# Pad our data to ensure consistent length\nX_train_padded = pad_sequences(X_train_sequences, maxlen=padding_length, padding='post', truncating='post')\nX_test_padded = pad_sequences(X_test_sequences, maxlen=padding_length, padding='post', truncating='post')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:37:53.121826Z","iopub.execute_input":"2023-11-20T22:37:53.122499Z","iopub.status.idle":"2023-11-20T22:38:23.236472Z","shell.execute_reply.started":"2023-11-20T22:37:53.122450Z","shell.execute_reply":"2023-11-20T22:38:23.235379Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:38:23.238275Z","iopub.execute_input":"2023-11-20T22:38:23.239125Z","iopub.status.idle":"2023-11-20T22:38:23.245061Z","shell.execute_reply.started":"2023-11-20T22:38:23.239079Z","shell.execute_reply":"2023-11-20T22:38:23.243821Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"['Aaa bbb ccc.' 'Bbb ccc ddd.' 'CCC ddd eee.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Visualizing our preprocessing\n\nNow we can see the three steps our data goes through\n","metadata":{}},{"cell_type":"code","source":"# essay_number = 5\n\n# print(\"Step 1: Raw Text\\n\"+ str(X_train[5]))\n# print(\"\\n\\nStep 2: Tokens\\n\" + str(X_train_sequences[essay_number]))\n# print(\"\\n\\nStep 3: Padded Set\\n\" + str(X_train_padded[essay_number]))\n\n# print(\"Generated? \" + str(bool(y_train[essay_number])))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:38:23.246611Z","iopub.execute_input":"2023-11-20T22:38:23.247060Z","iopub.status.idle":"2023-11-20T22:38:23.258190Z","shell.execute_reply.started":"2023-11-20T22:38:23.247019Z","shell.execute_reply":"2023-11-20T22:38:23.257063Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering\n\nAt this point, we can being to engineer out some new features that might give our model a nuanced idea of what is happening in the data.\n\nSome ideas I have right now:\n* Syntax and Grammar:\nUse language processing tools to analyze the syntactic structure and grammatical correctness of sentences. AI-generated text might exhibit patterns that deviate from human-like syntax.\n\n* Vocabulary Complexity:\nMeasure the complexity of vocabulary used in the text. AI models might generate text with either overly complex or simplistic language compared to typical human writing.\n* Semantic Coherence:\nAssess the coherence of sentences in terms of semantic meaning. Human-generated text tends to have a more natural flow of ideas and coherent structure.\n* Common Phrases and Idioms:\nCheck for the use of common phrases, idioms, and cultural references that are typically found in human communication. AI models may struggle to mimic these accurately.\n* Context Understanding:\nAnalyze the text for evidence of a deep understanding of context. Human writers often incorporate a broader contextual understanding into their writing that AI models may find challenging to replicate.\n* Creativity and Originality:\nAssess the level of creativity and originality in the text. Human writers often bring a unique perspective and creativity to their writing that may be distinct from AI-generated content.\n* Length and Structure:\nExamine the length and structure of sentences and paragraphs. AI models might produce text with consistent or repetitive structures that differ from the varied structures often found in human writing.\n* Consistency in Style:\nEvaluate the consistency in writing style throughout the text. Human writers may exhibit variations in style, tone, and expression, while AI-generated text might be more consistent.\n* Awareness of Current Events:\nCheck for references to recent events or time-sensitive information. AI models might not have up-to-date information or an understanding of current events.\n* Metaphors and Figurative Language:\nAnalyze the use of metaphors, similes, and other forms of figurative language. Human writers often use these elements to convey meaning in a nuanced way.","metadata":{}},{"cell_type":"markdown","source":"To combine these together, we can have a layer that combines our smaller parallel nodes and gives them different weight. I still believe that our raw text will have a large impact on its performance, but we want to supplement it with more valuable datapoints. \n\nFrom there, we need to bucket certain features together or keep them all seperate.","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Embedding(input_dim=10000, output_dim=128, input_length=200),\n    LSTM(64),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss =tf.keras.losses.BinaryCrossentropy(), metrics=[BinaryAccuracy()])","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:38:23.259614Z","iopub.execute_input":"2023-11-20T22:38:23.260127Z","iopub.status.idle":"2023-11-20T22:38:23.861057Z","shell.execute_reply.started":"2023-11-20T22:38:23.260085Z","shell.execute_reply":"2023-11-20T22:38:23.859817Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"y_train = y_train.astype(np.float32)\nif not isRealTest:\n    y_test  = y_test .astype(np.float32)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Train the model\nhistory = model.fit(X_train_padded, y_train, epochs=5, validation_split=0.1, callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2023-11-20T22:38:23.862532Z","iopub.execute_input":"2023-11-20T22:38:23.863494Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1154/1154 [==============================] - 126s 106ms/step - loss: 0.2260 - binary_accuracy: 0.9042 - val_loss: 0.0317 - val_binary_accuracy: 0.9937\nEpoch 2/5\n1154/1154 [==============================] - 121s 105ms/step - loss: 0.0420 - binary_accuracy: 0.9901 - val_loss: 0.0362 - val_binary_accuracy: 0.9932\nEpoch 3/5\n1097/1154 [===========================>..] - ETA: 5s - loss: 0.0261 - binary_accuracy: 0.9945","output_type":"stream"}]},{"cell_type":"code","source":"if not isRealTest:\n    # Evaluate the model on the test set\n    loss, accurtestcy = model.evaluate(X_test_padded, y_test)\n    print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\n# Predictions on the test set\ny_pred = model.predict(X_test_padded)\n\n# Convert probabilities to class labels\ny_pred_labels = np.round(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not isRealTest:\n    # Confusion matrix\n    conf_matrix = confusion_matrix(y_test, y_pred_labels)\n    print(\"Confusion Matrix:\")\n    print(conf_matrix)\n\n    # Classification report\n    class_report = classification_report(y_test, y_pred_labels)\n    print(\"\\nClassification Report:\")\n    print(class_report)\n\nif isRealTest:\n    submission = pd.DataFrame({'id': list(X_testIDs), 'generated': y_pred.flatten()})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}